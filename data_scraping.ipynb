{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\aditi\\anaconda3\\lib\\site-packages (2.22.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\aditi\\anaconda3\\lib\\site-packages (4.7.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aditi\\anaconda3\\lib\\site-packages (from requests) (2020.4.5.1)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\aditi\\anaconda3\\lib\\site-packages (from requests) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\aditi\\anaconda3\\lib\\site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\aditi\\anaconda3\\lib\\site-packages (from requests) (1.24.2)\n",
      "Requirement already satisfied: soupsieve>=1.2 in c:\\users\\aditi\\anaconda3\\lib\\site-packages (from beautifulsoup4) (1.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which stock are you interested in:\n",
      "\n",
      " Most Actives \n",
      "\n",
      "GE General Electric Co\n",
      "BAC Bank of America Corp\n",
      "F Ford Motor Co\n",
      "CCL Carnival Corp\n",
      "DAL Delta Air Lines Inc\n",
      "BA Boeing Co\n",
      "OXY Occidental Petroleum Corp\n",
      "MRO Marathon Oil Corp\n",
      "WFC Wells Fargo & Co\n",
      "C Citigroup Inc\n",
      "\n",
      " Gainers \n",
      "\n",
      "HFC HollyFrontier Corp\n",
      "MPC Marathon Petroleum Corp\n",
      "CFG Citizens Financial Group Inc\n",
      "CMA Comerica Inc\n",
      "VLO Valero Energy Corp\n",
      "HES Hess Corp\n",
      "ADS Alliance Data Systems Corp\n",
      "BA Boeing Co\n",
      "EOG EOG Resources Inc\n",
      "DVN Devon Energy Corp\n",
      "\n",
      " Losers \n",
      "\n",
      "UNH UnitedHealth Group Inc\n",
      "CNC Centene Corp\n",
      "CLX Clorox Co\n",
      "CPB Campbell Soup Co\n",
      "ANTM Anthem Inc\n",
      "NEM Newmont Corporation\n",
      "HUM Humana Inc\n",
      "KEYS Keysight Technologies Inc\n",
      "CI Cigna Corp\n",
      "WMT Walmart Inc\n",
      "\n",
      "Enter your Interested Company :  CLX\n",
      "\n",
      "\n",
      "The data for  CLX Clorox Co is the following:\n",
      "\n",
      "CLX Clorox Co\n",
      "Prev close: 196.49\n",
      "Open:  194.12\n",
      "Volume:  2361659\n",
      "Market Cap:  24.207B\n"
     ]
    }
   ],
   "source": [
    "import requests                       #importing the necessary packages\n",
    "from bs4 import BeautifulSoup \n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "def data_scrap(ticker):              # function definition\n",
    "    \n",
    "    PClose=''                         #creating the strings for the value sets needed\n",
    "    Open=''\n",
    "    Volume=''\n",
    "    Cap=''\n",
    "    scrapeddataset=[] \n",
    "\n",
    "    fin_url = 'https://finance.yahoo.com/quote/' + ticker + '?p=' + ticker   # yahoo url with ticker symbol\n",
    "    fin_req = requests.get(fin_url)                                          # sending request for url\n",
    "\n",
    "    fin_page = BeautifulSoup(fin_req.text, 'html.parser')                    # scrap html page using beatifulsoup\n",
    "\n",
    "    fin_data = fin_page.find_all(class_=\"Bxz(bb) Bdbw(1px) Bdbs(s) Bdc($seperatorColor) H(36px)\")  # filtering data of html page using class\n",
    "    \n",
    "    for val1 in fin_data:  \n",
    "        scrapeddataset += [a.text for a in val1.find_all(\"span\")] \n",
    "\n",
    "    for val2 in range(len(scrapeddataset)):               # accessing Open Price, Prev Close Price, Volume and Market Cap and storing them in variables\n",
    "\n",
    "        if(scrapeddataset[val2] == \"Previous Close\"): \n",
    "            PClose = scrapeddataset[val2+1]\n",
    "\n",
    "        if(scrapeddataset[val2] == \"Open\"): \n",
    "            Open = scrapeddataset[val2+1] \n",
    "\n",
    "        if(scrapeddataset[val2] == \"Volume\"): \n",
    "            Volume = scrapeddataset[val2+1]\n",
    "            Volume = re.sub(r'[^\\w\\s]','',Volume)\n",
    "\n",
    "        if(scrapeddataset[val2] == \"Market Cap\"):\n",
    "            Cap = scrapeddataset[val2+1]    \n",
    "    \n",
    "    return(PClose,Open,Volume,Cap)\n",
    "\n",
    "\n",
    "# main program starts here........\n",
    "\n",
    "\n",
    "try:\n",
    "                                                   \n",
    "    f=open(\"stocks.csv\",'w+')                      #creating file name and intiating write mode in file\n",
    "                                                   \n",
    "    comp_req = requests.get('https://money.cnn.com/data/hotstocks/')  #using the requests lib get the url for scrapping\n",
    "                                                   \n",
    "    comp_page = BeautifulSoup(comp_req.text, 'html.parser')  #using beautifulsoup library , scrapping the page using html.parser\n",
    "                                                   \n",
    "    comp_data = comp_page.find_all(class_=\"wsod_dataTable wsod_dataTableBigAlt\")  #using the find_all function filtering out all the data present with class specified \n",
    "\n",
    "    values =[]\n",
    "    title = ['Most Actives', 'Gainers', 'Losers'] \n",
    "    \n",
    "    for data in comp_data: \n",
    "        \n",
    "        #extracting all the needed data and values from the scrapped webpage using find_all func through for loop\n",
    "                                                   \n",
    "        [tmp.extract() for tmp in data.find_all(class_ = \"wsod_aRight\")]  \n",
    "        abbr = [a.text for a in data.find_all(class_= \"wsod_symbol\")] \n",
    "        name = [a.text for a in data.find_all(\"span\")] \n",
    "        values += [dict(zip(abbr, name))]                        # arranging the data set using dict func\n",
    "\n",
    "       \n",
    "    finaldata = dict(zip(title, values))         #this list contains company ticker symbols and name sorted using dict func \n",
    "\n",
    "    space=' '\n",
    "    count=0\n",
    "\n",
    "    print(\"Which stock are you interested in:\")\n",
    "\n",
    "    while count<=2:\n",
    "        \n",
    "        fd=finaldata[title[count]]\n",
    "        title_val=(title[count])\n",
    "        print('\\n',title_val,'\\n') \n",
    "        \n",
    "        f.write(title_val)      # storing titles: Most Actives, Gainers and Losers in file.\n",
    "        f.write('\\n\\n')\n",
    "        \n",
    "        for i in fd:\n",
    "\n",
    "            print(i,fd[i])   # printing ticker symbol and company name\n",
    "\n",
    "                    #print(i)\n",
    "            PClose,Open,Volume,Cap = data_scrap(i)  # call function to scrap data based on ticker symbol\n",
    "                        \n",
    "            outputs=i,',',fd[i],',',PClose,',',Open,',',Volume,',',Cap,'\\n'\n",
    "            add_space=space.join(outputs)\n",
    "\n",
    "            f.write(add_space)\n",
    "                        \n",
    "\n",
    "        count=count+1\n",
    "    f.close()          # closing file here\n",
    "\n",
    "    while True:\n",
    "        temp_val = False\n",
    "\n",
    "        symbol_inp = input(\"\\nEnter your Interested Company :  \")    #asking user to input the company name \n",
    "        symbol_inp = symbol_inp.upper()\n",
    "        \n",
    "        file_open=open('stocks.csv')                                 # open file\n",
    "        words=file_open.read().strip().split('\\n')\n",
    "        for a in words:\n",
    "            line=a.split(',')\n",
    "            \n",
    "            for b in line:\n",
    "                symbol=b.strip()\n",
    "\n",
    "                    #print(ask)\n",
    "                if (symbol==symbol_inp):\n",
    "                    PClose,Open,Volume,Cap = data_scrap(symbol_inp)             #call scrap function again to get data from website\n",
    "                    \n",
    "                    print('\\n')\n",
    "                    print(\"The data for \",line[0].strip(),line[1].strip(),\"is the following:\\n\")\n",
    "                    print(line[0].strip(),line[1].strip())\n",
    "                    print('Prev close:',  PClose)\n",
    "                    print('Open: ', Open)\n",
    "                    print('Volume: ', Volume)\n",
    "                    print('Market Cap: ', Cap)\n",
    "                    temp_val = True\n",
    "                    break\n",
    "                    \n",
    "            if (symbol==symbol_inp):\n",
    "                break\n",
    "\n",
    "        if temp_val:\n",
    "            break\n",
    "        else:\n",
    "            print (\"\\nYou did not enter correct ticker symbol from the list.\")\n",
    "except:\n",
    "    print(\"Please re run the code!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
