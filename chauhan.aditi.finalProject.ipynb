{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINAL PROJECT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm\n",
    "\n",
    "- 1: Install beautifulsoup 4 library.\n",
    "- 2: Import all the necessary libraries: requests and re.\n",
    "- 3: Open file 'stocks.csv' in write mode.\n",
    "- 4: Using the requests lib get the url for scrapping: https://money.cnn.com/data/hotstocks/\n",
    "- 5: Using beautifulsoup library , scrap the page using html.parser.\n",
    "- 6: Extract ticker symbol and company name from parsed page and store it in dictionary.\n",
    "- 7: Under each title, get the company information for each ticker symbol using loop.\n",
    "- 8: Call function 'data_scrap' with ticker symbol as its argument.\n",
    "- 9: 'data_scrap' function will scrape data from website https://in.finance.yahoo.com/quote/ as in step 4 and step 5. It will return four values.\n",
    "- 10: Write company name, ticker symbol, open, previous close, market cap and volume in csv file. \n",
    "- 11: Close the file after writing all the values.\n",
    "- 12: Ask user to enter one ticker symbol from the list.\n",
    "- 13: If entered ticker symbol is found in the csv file, print the information of the company and finish the program.\n",
    "- 14: else, ask user to enter valid ticker symbol.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## CODE INSTRUCTIONS:\n",
    "\n",
    "- Execute cell which has Installation command for  beatifulsoup library at first. \n",
    "- After that, Start the program by selecting the cell. \n",
    "- Program will ask for user input. If the input is correct it will display the data and finish the program. To check for different results, run the program again.\n",
    "- If user has entered wrong output, program will ask for input until it's correct.\n",
    "- Input is NOT case sensitive.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## EXPECTED RESULT:\n",
    "\n",
    "        Enter your Interested Company :  ll\n",
    "\n",
    "        You did not enter correct ticker symbol from the list.\n",
    "    \n",
    "        Enter your Interested Company :  HP\n",
    "\n",
    "\n",
    "        The data for  HP Helmerich and Payne Inc is the following:\n",
    "\n",
    "        HP Helmerich and Payne Inc\n",
    "        Prev close: 40.46\n",
    "        Open:  39.91\n",
    "        Volume:  1490909\n",
    "        Market Cap:  4.287B\n",
    "        \n",
    "        \n",
    "        \n",
    "## NOTE:\n",
    "There is a possibility that sometimes program terminates and results in output 'Run the program again'. This might happen because of reasons: \n",
    "- Internet connection- Check if you are connected to the internet and then restart the kernal and try to run program again.\n",
    "- Website data changes- At a certain time in a day, data gets changed on website because of which requested url do not return expected output. Wait for sometime restart the kernal and try to run program again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install requests beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which stock are you interested in:\n",
      "\n",
      " Most Actives \n",
      "\n",
      "GE General Electric Co\n",
      "BAC Bank of America Corp\n",
      "T AT&T Inc\n",
      "AMD Advanced Micro Devices Inc\n",
      "F Ford Motor Co\n",
      "MSFT Microsoft Corp\n",
      "AAPL Apple Inc\n",
      "BMY Bristol-Myers Squibb Co\n",
      "FCX Freeport-McMoRan Inc\n",
      "HPQ HP Inc\n",
      "\n",
      " Gainers \n",
      "\n",
      "NRG NRG Energy Inc\n",
      "HPQ HP Inc\n",
      "CF CF Industries Holdings Inc\n",
      "DXC DXC Technology Co\n",
      "CME CME Group Inc\n",
      "CRM Salesforce.Com Inc\n",
      "DRI Darden Restaurants Inc\n",
      "ICE Intercontinental Exchange Inc\n",
      "VRTX Vertex Pharmaceuticals Inc\n",
      "ATVI Activision Blizzard Inc\n",
      "\n",
      " Losers \n",
      "\n",
      "APA Apache Corp\n",
      "FTI TechnipFMC PLC\n",
      "DVN Devon Energy Corp\n",
      "KSS Kohls Corp\n",
      "HP Helmerich and Payne Inc\n",
      "NBL Noble Energy Inc\n",
      "URI United Rentals Inc\n",
      "HBI HanesBrands Inc\n",
      "LYB LyondellBasell Industries NV\n",
      "EOG EOG Resources Inc\n",
      "\n",
      "Enter your Interested Company :  hjh\n",
      "\n",
      "You did not enter correct ticker symbol from the list.\n",
      "\n",
      "Enter your Interested Company :  k\n",
      "\n",
      "You did not enter correct ticker symbol from the list.\n",
      "\n",
      "Enter your Interested Company :  T\n",
      "\n",
      "\n",
      "The data for  T AT&T Inc is the following:\n",
      "\n",
      "T AT&T Inc\n",
      "Prev close: 37.66\n",
      "Open:  37.74\n",
      "Volume:  18172510\n",
      "Market Cap:  273.061B\n"
     ]
    }
   ],
   "source": [
    "import requests                       #importing the necessary packages\n",
    "from bs4 import BeautifulSoup \n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "def data_scrap(ticker):              # function definition\n",
    "    \n",
    "    PClose=''                         #creating the strings for the value sets needed\n",
    "    Open=''\n",
    "    Volume=''\n",
    "    Cap=''\n",
    "    scrapeddataset=[] \n",
    "\n",
    "    fin_url = 'https://finance.yahoo.com/quote/' + ticker + '?p=' + ticker   # yahoo url with ticker symbol\n",
    "    fin_req = requests.get(fin_url)                                          # sending request for url\n",
    "\n",
    "    fin_page = BeautifulSoup(fin_req.text, 'html.parser')                    # scrap html page using beatifulsoup\n",
    "\n",
    "    fin_data = fin_page.find_all(class_=\"Bxz(bb) Bdbw(1px) Bdbs(s) Bdc($seperatorColor) H(36px)\")  # filtering data of html page using class\n",
    "    \n",
    "    for val1 in fin_data:  \n",
    "        scrapeddataset += [a.text for a in val1.find_all(\"span\")] \n",
    "\n",
    "    for val2 in range(len(scrapeddataset)):               # accessing Open Price, Prev Close Price, Volume and Market Cap and storing them in variables\n",
    "\n",
    "        if(scrapeddataset[val2] == \"Previous Close\"): \n",
    "            PClose = scrapeddataset[val2+1]\n",
    "\n",
    "        if(scrapeddataset[val2] == \"Open\"): \n",
    "            Open = scrapeddataset[val2+1] \n",
    "\n",
    "        if(scrapeddataset[val2] == \"Volume\"): \n",
    "            Volume = scrapeddataset[val2+1]\n",
    "            Volume = re.sub(r'[^\\w\\s]','',Volume)\n",
    "\n",
    "        if(scrapeddataset[val2] == \"Market Cap\"):\n",
    "            Cap = scrapeddataset[val2+1]    \n",
    "    \n",
    "    return(PClose,Open,Volume,Cap)\n",
    "\n",
    "\n",
    "# main program starts here........\n",
    "\n",
    "\n",
    "try:\n",
    "                                                   \n",
    "    f=open(\"stocks.csv\",'w+')                      #creating file name and intiating write mode in file\n",
    "                                                   \n",
    "    comp_req = requests.get('https://money.cnn.com/data/hotstocks/')  #using the requests lib get the url for scrapping\n",
    "                                                   \n",
    "    comp_page = BeautifulSoup(comp_req.text, 'html.parser')  #using beautifulsoup library , scrapping the page using html.parser\n",
    "                                                   \n",
    "    comp_data = comp_page.find_all(class_=\"wsod_dataTable wsod_dataTableBigAlt\")  #using the find_all function filtering out all the data present with class specified \n",
    "\n",
    "    values =[]\n",
    "    title = ['Most Actives', 'Gainers', 'Losers'] \n",
    "    \n",
    "    for data in comp_data: \n",
    "        \n",
    "        #extracting all the needed data and values from the scrapped webpage using find_all func through for loop\n",
    "                                                   \n",
    "        [tmp.extract() for tmp in data.find_all(class_ = \"wsod_aRight\")]  \n",
    "        abbr = [a.text for a in data.find_all(class_= \"wsod_symbol\")] \n",
    "        name = [a.text for a in data.find_all(\"span\")] \n",
    "        values += [dict(zip(abbr, name))]                        # arranging the data set using dict func\n",
    "\n",
    "       \n",
    "    finaldata = dict(zip(title, values))         #this list contains company ticker symbols and name sorted using dict func \n",
    "\n",
    "    space=' '\n",
    "    count=0\n",
    "\n",
    "    print(\"Which stock are you interested in:\")\n",
    "\n",
    "    while count<=2:\n",
    "        \n",
    "        fd=finaldata[title[count]]\n",
    "        title_val=(title[count])\n",
    "        print('\\n',title_val,'\\n') \n",
    "        \n",
    "        f.write(title_val)      # storing titles: Most Actives, Gainers and Losers in file.\n",
    "        f.write('\\n\\n')\n",
    "        \n",
    "        for i in fd:\n",
    "\n",
    "            print(i,fd[i])   # printing ticker symbol and company name\n",
    "\n",
    "                    #print(i)\n",
    "            PClose,Open,Volume,Cap = data_scrap(i)  # call function to scrap data based on ticker symbol\n",
    "                        \n",
    "            outputs=i,',',fd[i],',',PClose,',',Open,',',Volume,',',Cap,'\\n'\n",
    "            add_space=space.join(outputs)\n",
    "\n",
    "            f.write(add_space)\n",
    "                        \n",
    "\n",
    "        count=count+1\n",
    "    f.close()          # closing file here\n",
    "\n",
    "    while True:\n",
    "        temp_val = False\n",
    "\n",
    "        symbol_inp = input(\"\\nEnter your Interested Company :  \")    #asking user to input the company name \n",
    "        symbol_inp = symbol_inp.upper()\n",
    "        \n",
    "        file_open=open('stocks.csv')                                 # open file\n",
    "        words=file_open.read().strip().split('\\n')\n",
    "        for a in words:\n",
    "            line=a.split(',')\n",
    "            \n",
    "            for b in line:\n",
    "                symbol=b.strip()\n",
    "\n",
    "                    #print(ask)\n",
    "                if (symbol==symbol_inp):\n",
    "                    PClose,Open,Volume,Cap = data_scrap(symbol_inp)             #call scrap function again to get data from website\n",
    "                    \n",
    "                    print('\\n')\n",
    "                    print(\"The data for \",line[0].strip(),line[1].strip(),\"is the following:\\n\")\n",
    "                    print(line[0].strip(),line[1].strip())\n",
    "                    print('Prev close:',  PClose)\n",
    "                    print('Open: ', Open)\n",
    "                    print('Volume: ', Volume)\n",
    "                    print('Market Cap: ', Cap)\n",
    "                    temp_val = True\n",
    "                    break\n",
    "                    \n",
    "            if (symbol==symbol_inp):\n",
    "                break\n",
    "\n",
    "        if temp_val:\n",
    "            break\n",
    "        else:\n",
    "            print (\"\\nYou did not enter correct ticker symbol from the list.\")\n",
    "except:\n",
    "    print(\"Please re run the code!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
